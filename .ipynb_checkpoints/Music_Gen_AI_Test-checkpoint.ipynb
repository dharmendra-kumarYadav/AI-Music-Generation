{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "notes_df = pd.read_csv ('Dataset/notes.csv')\n",
    "test_df = pd.read_csv ('Dataset/testset.csv')\n",
    "\n",
    "data_test = test_df[['x_test','future']].to_numpy()\n",
    "\n",
    "x_test_string = data_test[:,0]\n",
    "y_test_string = data_test[:,1]\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in x_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "\n",
    "\n",
    "notes_ = notes_df.to_numpy()[:,1]\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))\n",
    "# unique_notes = {value : key for (key, value) in unique_notes_reverse.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MusicDataset import *\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(\n",
      "  (embedding): Embedding(182, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True)\n",
      "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (linear3): Linear(in_features=128, out_features=182, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Specify the file path of the model to load\n",
    "model_file = 'trained_model_cache/10_04_2024_11_56/model1.pth'\n",
    "\n",
    "# Load the model\n",
    "Net = torch.load(model_file, map_location='cpu')\n",
    "\n",
    "# Print the loaded model\n",
    "print(Net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:\n",
      "Correct Predictions: 6842 \n",
      "Total Predictions: 62712 \n",
      "Testing Accuracy: 10.910192626610538 \n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    input, label = data\n",
    "    cumm_output = torch.zeros(0, len(unique_notes)).to(device)\n",
    "    cumm_label = np.array([], dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        # Forward pass through the model\n",
    "        output = Net(input.to(device), input.shape[0])  # Corrected call to model's forward method\n",
    "        cumm_output = torch.cat((cumm_output, output))\n",
    "        cumm_label = np.concatenate((cumm_label, label[:, k]))\n",
    "        # Calculate accuracy\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output, 1) == label[:, k].to(device))\n",
    "        input = torch.from_numpy(np.array([np.append(j, np.argmax(output.cpu().detach().numpy(), axis=1)[ind]) for ind, j in enumerate(input)])[:, 1:])\n",
    "test_acc = float(correct_preds) / float(total_preds) * 100 \n",
    "testreport = \"Testing Accuracy:\\nCorrect Predictions: {} \\nTotal Predictions: {} \\nTesting Accuracy: {} \\n------------------------\\n\".format(correct_preds, total_preds, test_acc)\n",
    "print(testreport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[  7 127  15   7 115 132   7  97  15 127   7 132  85 179  15 105 132 179\n",
      " 105  15 179  85 132 105 179 110  46  94  11  82  94 110]\n",
      "Taking the seed tune as follows:\n",
      "[117  60  78  66  60 128  78  52  60 117  78  19 152  60  78  37 160  60\n",
      "  78  78  78  78  78  19  60 152  52 117  19 152 177  78]\n",
      "Taking the seed tune as follows:\n",
      "[136  14 144 136  14  50  14  50  91 117  50  91   9 144  91   9  35   9\n",
      "  35   9 152  80  35   9 144  35  80 159 179 180 166 131]\n",
      "Taking the seed tune as follows:\n",
      "[153 105 129 153 159 129 110 153  66 129   7 100 129  53  66  51   7 110\n",
      " 153  37  49 166  87 105  37 179  28   5  46 112  29 179]\n",
      "Taking the seed tune as follows:\n",
      "[ 71   7  45  53  60  37  16 115  60  52  16  36  60 155  16 173  60 130\n",
      "  36  20 130  63  60  26  20   7  60  85  20  53  60  37]\n",
      "Taking the seed tune as follows:\n",
      "[150 103 165  46 150  45  13  46 150 134 151 179 137  45  13 137  45  13\n",
      " 137  45  13 179  85 137  45 179  13 179 137 103  46 165]\n",
      "Taking the seed tune as follows:\n",
      "[  8 117 155 178  78 155 178 152   0 126 116  73 126  49  78 155 129  78\n",
      "  68   8  60 155 179 117 179 155 179 179  78 179 155 179]\n",
      "Taking the seed tune as follows:\n",
      "[165  82 136  45  71 136  13  35  35 160  17  35  13  46  91 134 136  91\n",
      " 165  46  35 131  14  35  71  46  35  13  14  35  71  94]\n",
      "Taking the seed tune as follows:\n",
      "[176  61 137  41   5  87  23  95  99  28 178 112  44  87  28  87  28  87\n",
      "  51  28   5  87  51  28 178  82  99  28 157  87   5 118]\n",
      "Taking the seed tune as follows:\n",
      "[  7 166 159  82  66  50 123  50 158  82 159 159 158 166 166 179 153 153\n",
      " 159 158 166 166 159 111 105 105 159 180 180 159 179 179]\n"
     ]
    }
   ],
   "source": [
    "# Time to generate some Music!!!\n",
    "import random\n",
    "from Dataset import midi_helper \n",
    "for j in range(10):\n",
    "    index = random.randint(0,len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1,32),dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device),input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                                   for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "        tune = np.insert(tune,-1,next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = './Outputs/music' + str(j) + '.midi'\n",
    "    midi_helper.convert_to_midi(tune, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming you have the necessary DataLoader for validation data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m validationloader \u001b[38;5;241m=\u001b[39m DataLoader(validation_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/checkpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the necessary DataLoader for validation data\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the trained model\n",
    "checkpoint = torch.load('path/to/checkpoint.pth')\n",
    "model = checkpoint['model']\n",
    "model.eval()\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define class names\n",
    "class_names = [...]  # Fill this with your class names\n",
    "\n",
    "# Function to calculate and plot confusion matrix\n",
    "def create_confusion_matrix(model, dataloader, classes, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_confusion_matrix(cm, classes=classes, title='Confusion matrix')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_confusion_matrix(cm, classes=classes, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to create and plot the confusion matrix\n",
    "create_confusion_matrix(model, validationloader, class_names, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
