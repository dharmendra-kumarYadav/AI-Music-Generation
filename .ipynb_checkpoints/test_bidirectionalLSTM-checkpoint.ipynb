{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d9989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa2773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "notes_df = pd.read_csv ('Dataset/notes.csv')\n",
    "test_df = pd.read_csv ('Dataset/testset.csv')\n",
    "\n",
    "data_test = test_df[['x_test','future']].to_numpy()\n",
    "\n",
    "x_test_string = data_test[:,0]\n",
    "y_test_string = data_test[:,1]\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in x_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "notes_ = notes_df.to_numpy()[:,1]\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))\n",
    "# unique_notes = {value : key for (key, value) in unique_notes_reverse.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46251e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MusicDataset import *\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd394cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(\n",
      "  (embedding): Embedding(10, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Sequence(\n",
      "  (embedding): Embedding(10, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Sequence(\n",
      "  (embedding): Embedding(182, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=182, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Specify the file path of the model to load\n",
    "model_file = 'trained_model_cache/03_04_2024_16_47/model1.pth'\n",
    "\n",
    "# Load the model\n",
    "Net = torch.load(model_file, map_location='cpu')\n",
    "\n",
    "# Print the loaded model\n",
    "print(Net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4c8290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:\n",
      "Correct Predictions: 7089 \n",
      "Total Predictions: 62712 \n",
      "Testing Accuracy: 11.304056639877535 \n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    input, label = data\n",
    "    cumm_output = torch.zeros(0, len(unique_notes)).to(device)\n",
    "    cumm_label = np.array([], dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        # Forward pass through the model\n",
    "        output = Net(input.to(device))  # Corrected call to model's forward method\n",
    "        cumm_output = torch.cat((cumm_output, output))\n",
    "        cumm_label = np.concatenate((cumm_label, label[:, k]))\n",
    "        # Calculate accuracy\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output, 1) == label[:, k].to(device))\n",
    "        input = torch.from_numpy(np.array([np.append(j, np.argmax(output.cpu().detach().numpy(), axis=1)[ind]) for ind, j in enumerate(input)])[:, 1:])\n",
    "test_acc = float(correct_preds) / float(total_preds) * 100 \n",
    "testreport = \"Testing Accuracy:\\nCorrect Predictions: {} \\nTotal Predictions: {} \\nTesting Accuracy: {} \\n------------------------\\n\".format(correct_preds, total_preds, test_acc)\n",
    "print(testreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d0a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 80  35   9 128  50 136  17 103 123 128 144  60  14 160 136 152  17 103\n",
      "  14 160 136 152  17 103  14 160 136 152  17 103  14 160]\n",
      "Taking the seed tune as follows:\n",
      "[ 78  54 133 134  78 165  78  54 114 134 160 165 160  17 136 151  82 136\n",
      " 159 123 180 165   7  78  26 152  63 128 119 134  90 174]\n",
      "Taking the seed tune as follows:\n",
      "[ 53 127  77 115   7  15 132   7  37  53   7  66 166 179  37 179  66 179\n",
      "  66  58  66  58  52  16  53  37 115  16 102  18 115 102]\n",
      "Taking the seed tune as follows:\n",
      "[147 153 166 109 147 147 147 147  40  76  36 109 147 147 147 147  93  72\n",
      " 147 159  78 159 109  46 159  78  76 109 159  78  46 159]\n",
      "Taking the seed tune as follows:\n",
      "[ 72 155   7  50  53 155  50 155 144 166 155 165 166 155 144 166 155  73\n",
      " 153 155 165 153 144 155 123 153  54 155 144 166 155 123]\n",
      "Taking the seed tune as follows:\n",
      "[ 94  54   9   9  54 159  94  14 159  46  17  76  76  42  42  42  42 122\n",
      " 122 135 135 168 135  92 145  12  93 111 129 109 128 142]\n",
      "Taking the seed tune as follows:\n",
      "[ 78 163  13  17  50 131  17  13  78  13  17  13 177 131  17  50  35 131\n",
      "  50  17  13  17  50  54 138 131  50  35 136 131  91  35]\n",
      "Taking the seed tune as follows:\n",
      "[139 142  22 149 149 110 160 128 158  66  19  19  82 158  19  11 155 100\n",
      "  37 124  80 155  37 172 128  72  11  10 128  38 172   9]\n",
      "Taking the seed tune as follows:\n",
      "[ 49  50  82  50  97  49  14  91  35  91  35  82   7  69  50 115   7  97\n",
      "  14  69   7 127   7 127  26   7  49  50  82  50  97  49]\n",
      "Taking the seed tune as follows:\n",
      "[ 17  14 105 144  14 105  17  14 105 165  14 105  17  14 105  73  14 105\n",
      "  17  14 166  78  50  54  50  78   9 136 153   9 166  78]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Create bidirectionalOutputs directory if it doesn't exist\n",
    "output_dir = \"./bidirectionalOutputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for j in range(10):\n",
    "    index = random.randint(0,len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1,32),dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                                   for ind,j in enumerate(input)])[:,1:]) \n",
    "        tune = np.insert(tune,-1,next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = './bidirectionalOutputs/music' + str(j) + '.midi'\n",
    "    midi_helper.convert_to_midi(tune, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b65624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
