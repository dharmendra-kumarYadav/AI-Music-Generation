{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b83faff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bb1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "notes_df = pd.read_csv ('Dataset/notes.csv')\n",
    "test_df = pd.read_csv ('Dataset/testset.csv')\n",
    "\n",
    "data_test = test_df[['x_test','future']].to_numpy()\n",
    "\n",
    "x_test_string = data_test[:,0]\n",
    "y_test_string = data_test[:,1]\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in x_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "notes_ = notes_df.to_numpy()[:,1]\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))\n",
    "# unique_notes = {value : key for (key, value) in unique_notes_reverse.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b378d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MusicDataset import *\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df773b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(\n",
      "  (embedding): Embedding(10, 100)\n",
      "  (lstms): ModuleList(\n",
      "    (0): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "    (1-2): 2 x LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Sequence(\n",
      "  (embedding): Embedding(182, 100)\n",
      "  (lstms): ModuleList(\n",
      "    (0): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "    (1-2): 2 x LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=182, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Specify the file path of the model to load\n",
    "model_file = 'trained_model_cache/04_04_2024_00_04/model1.pth'\n",
    "\n",
    "# Load the model\n",
    "Net = torch.load(model_file, map_location='cpu')\n",
    "\n",
    "# Print the loaded model\n",
    "print(Net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f90691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:\n",
      "Correct Predictions: 6866 \n",
      "Total Predictions: 62712 \n",
      "Testing Accuracy: 10.948462814134457 \n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    input, label = data\n",
    "    cumm_output = torch.zeros(0, len(unique_notes)).to(device)\n",
    "    cumm_label = np.array([], dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        # Forward pass through the model\n",
    "        output = Net(input.to(device))  # Corrected call to model's forward method\n",
    "        cumm_output = torch.cat((cumm_output, output))\n",
    "        cumm_label = np.concatenate((cumm_label, label[:, k]))\n",
    "        # Calculate accuracy\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output, 1) == label[:, k].to(device))\n",
    "        input = torch.from_numpy(np.array([np.append(j, np.argmax(output.cpu().detach().numpy(), axis=1)[ind]) for ind, j in enumerate(input)])[:, 1:])\n",
    "test_acc = float(correct_preds) / float(total_preds) * 100 \n",
    "testreport = \"Testing Accuracy:\\nCorrect Predictions: {} \\nTotal Predictions: {} \\nTesting Accuracy: {} \\n------------------------\\n\".format(correct_preds, total_preds, test_acc)\n",
    "print(testreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5262fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 75  75   0 107   0  59 149 180 179  55  83 159 180 179 149 126 179 129\n",
      " 180 109  29  59   0  37  99 126   0  77   0  59 149 180]\n",
      "Taking the seed tune as follows:\n",
      "[ 14  46  73 105  46  14 165  46  14  46   9 105  46  82 165  46  82  46\n",
      "   9   7  46  46 165   7  46   7   9  18   7 118  49 112]\n",
      "Taking the seed tune as follows:\n",
      "[177 165 134  78 177 165 134  78 177 165 134  78 177   5 151  13  93 165\n",
      "  71  17  93  69  14  91  35  95  82  94  46  28 179 105]\n",
      "Taking the seed tune as follows:\n",
      "[152 152 100 140 100 140  70 131 100 140  70 131 152 152 152 136 128 136\n",
      " 128  50 103 136 128  50 103 152 136 128 136 128  70 152]\n",
      "Taking the seed tune as follows:\n",
      "[ 33 102 128  90  33  98 102  26  53  22 153 166  78 136 123 165  78 152\n",
      " 128  78 115  60  18  16 115  18 115  36  16 115  26 117]\n",
      "Taking the seed tune as follows:\n",
      "[110  93   8 110   8 100  51 100  51 126 178  57 126 178  57 178 132 129\n",
      " 132 129   0  88  49  69   0  29  22   5  37 129 110  88]\n",
      "Taking the seed tune as follows:\n",
      "[ 28 155 155 100 100 100 100 132 132 100 100  75  75  49  59 129  59 129\n",
      "  37  29  29 155   8 155  52 155  52  37  37  37  93  37]\n",
      "Taking the seed tune as follows:\n",
      "[ 71  14  35  14  71  14  71  14  35  14  71  94  57  71 136  91 136  71\n",
      "  46  67  14  91  80  91  14 105 156  14  91  94  91  14]\n",
      "Taking the seed tune as follows:\n",
      "[180 123  46 144 159  13  46 144 159  13  46 144 180 123 166  17  85 136\n",
      "  97  50 169 169 169 169 169 169 118 118 118 118 118 118]\n",
      "Taking the seed tune as follows:\n",
      "[152 152 100 140 100 140  70 131 100 140  70 131 152 152 152 136 128 136\n",
      " 128  50 103 136 128  50 103 152 136 128 136 128  70 152]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from Dataset import midi_helper\n",
    "\n",
    "# Create bidirectionalOutputs directory if it doesn't exist\n",
    "output_dir = \"./stackedOutputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for j in range(10):\n",
    "    index = random.randint(0,len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1,32),dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                                   for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "        tune = np.insert(tune,-1,next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = './stackedOutputs/music' + str(j) + '.midi'\n",
    "    midi_helper.convert_to_midi(tune, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995b6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
